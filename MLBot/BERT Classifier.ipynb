{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1bffe87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bibliographic-worcester",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46c9304e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['label', 'text', 'labels'],\n",
       "    num_rows: 33\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LABELS = {\n",
    "    '__label__temperature': 0,\n",
    "    '__label__ethereum': 1,\n",
    "    '__label__help': 2\n",
    "}\n",
    "\n",
    "with open('./utterances.txt', 'r') as data_file:\n",
    "    lines = data_file.readlines()\n",
    "    lines = [ [line.split(' ')[0], ' '.join(line.split(' ')[1:]).replace('\\n', '') ] for line in lines ]\n",
    "    data = pd.DataFrame(lines, columns=['label', 'text'])\n",
    "\n",
    "data['labels'] = data['label'].apply(lambda v: LABELS[v])\n",
    "    \n",
    "dataset = Dataset.from_pandas(data)\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bacf5a85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1435552e86914e5283c7b54231df1a11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7f17908208>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "def tokenize(records):\n",
    "    return tokenizer(records['text'], padding='max_length', truncation=True)\n",
    "\n",
    "dataset = dataset.map(tokenize, batched=True)\n",
    "dataset = dataset.remove_columns(['text', 'label'])\n",
    "dataset.set_format('torch')\n",
    "\n",
    "dataloader = DataLoader(dataset, shuffle=True, batch_size=4)\n",
    "\n",
    "dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5713b002",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_transform.weight', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_layer_norm.weight']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DistilBertModel(\n",
       "  (embeddings): Embeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (transformer): Transformer(\n",
       "    (layer): ModuleList(\n",
       "      (0): TransformerBlock(\n",
       "        (attention): MultiHeadSelfAttention(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (ffn): FFN(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (activation): GELUActivation()\n",
       "        )\n",
       "        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (1): TransformerBlock(\n",
       "        (attention): MultiHeadSelfAttention(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (ffn): FFN(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (activation): GELUActivation()\n",
       "        )\n",
       "        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (2): TransformerBlock(\n",
       "        (attention): MultiHeadSelfAttention(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (ffn): FFN(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (activation): GELUActivation()\n",
       "        )\n",
       "        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (3): TransformerBlock(\n",
       "        (attention): MultiHeadSelfAttention(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (ffn): FFN(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (activation): GELUActivation()\n",
       "        )\n",
       "        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (4): TransformerBlock(\n",
       "        (attention): MultiHeadSelfAttention(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (ffn): FFN(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (activation): GELUActivation()\n",
       "        )\n",
       "        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (5): TransformerBlock(\n",
       "        (attention): MultiHeadSelfAttention(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (ffn): FFN(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (activation): GELUActivation()\n",
       "        )\n",
       "        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_model = AutoModel.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "for parameter in embedding_model.parameters():\n",
    "    parameter.requires_grad = False\n",
    "    \n",
    "embedding_model.eval()\n",
    "\n",
    "embedding_model = embedding_model.to(device)\n",
    "\n",
    "def embed(input_ids, attention_mask, labels=None):\n",
    "    with torch.no_grad():\n",
    "        return embedding_model(input_ids=input_ids, attention_mask=attention_mask).last_hidden_state[:, 0, :]\n",
    "\n",
    "embedding_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3f77f95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=768, out_features=64, bias=True)\n",
       "  (1): LeakyReLU(negative_slope=0.01)\n",
       "  (2): Dropout(p=0.1, inplace=False)\n",
       "  (3): Linear(in_features=64, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = nn.Sequential(\n",
    "    nn.Linear(768, 64),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.Dropout(0.1),\n",
    "    nn.Linear(64, 3))\n",
    "\n",
    "classifier = classifier.to(device)\n",
    "\n",
    "classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "checked-photographer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_device(batch):\n",
    "    return {key: value.to(device) for key, value in batch.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9fd0594c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10, Batch: 0, Error: 1.1225906610488892\n",
      "Epoch: 1/10, Batch: 1, Error: 1.083631992340088\n",
      "Epoch: 1/10, Batch: 2, Error: 1.0528229475021362\n",
      "Epoch: 1/10, Batch: 3, Error: 1.0556509494781494\n",
      "Epoch: 1/10, Batch: 4, Error: 1.1698664426803589\n",
      "Epoch: 1/10, Batch: 5, Error: 1.0155810117721558\n",
      "Epoch: 1/10, Batch: 6, Error: 1.127977728843689\n",
      "Epoch: 1/10, Batch: 7, Error: 1.1153796911239624\n",
      "Epoch: 1/10, Batch: 8, Error: 1.174458384513855\n",
      "Epoch: 2/10, Batch: 0, Error: 1.0215530395507812\n",
      "Epoch: 2/10, Batch: 1, Error: 0.9776033759117126\n",
      "Epoch: 2/10, Batch: 2, Error: 1.0517340898513794\n",
      "Epoch: 2/10, Batch: 3, Error: 0.8726167678833008\n",
      "Epoch: 2/10, Batch: 4, Error: 1.093069076538086\n",
      "Epoch: 2/10, Batch: 5, Error: 1.1211233139038086\n",
      "Epoch: 2/10, Batch: 6, Error: 1.0025044679641724\n",
      "Epoch: 2/10, Batch: 7, Error: 1.0986778736114502\n",
      "Epoch: 2/10, Batch: 8, Error: 0.8576810359954834\n",
      "Epoch: 3/10, Batch: 0, Error: 0.8332641124725342\n",
      "Epoch: 3/10, Batch: 1, Error: 1.090179204940796\n",
      "Epoch: 3/10, Batch: 2, Error: 0.8591821789741516\n",
      "Epoch: 3/10, Batch: 3, Error: 0.9432610869407654\n",
      "Epoch: 3/10, Batch: 4, Error: 0.9851265549659729\n",
      "Epoch: 3/10, Batch: 5, Error: 0.8127131462097168\n",
      "Epoch: 3/10, Batch: 6, Error: 0.9596561193466187\n",
      "Epoch: 3/10, Batch: 7, Error: 0.9286556243896484\n",
      "Epoch: 3/10, Batch: 8, Error: 0.7671046257019043\n",
      "Epoch: 4/10, Batch: 0, Error: 0.8492900133132935\n",
      "Epoch: 4/10, Batch: 1, Error: 0.8376948237419128\n",
      "Epoch: 4/10, Batch: 2, Error: 0.791293740272522\n",
      "Epoch: 4/10, Batch: 3, Error: 0.7706177830696106\n",
      "Epoch: 4/10, Batch: 4, Error: 0.6609295010566711\n",
      "Epoch: 4/10, Batch: 5, Error: 0.6787421107292175\n",
      "Epoch: 4/10, Batch: 6, Error: 1.037096381187439\n",
      "Epoch: 4/10, Batch: 7, Error: 1.0666178464889526\n",
      "Epoch: 4/10, Batch: 8, Error: 1.2507908344268799\n",
      "Epoch: 5/10, Batch: 0, Error: 0.7216931581497192\n",
      "Epoch: 5/10, Batch: 1, Error: 0.7673062086105347\n",
      "Epoch: 5/10, Batch: 2, Error: 0.6426613330841064\n",
      "Epoch: 5/10, Batch: 3, Error: 0.7632760405540466\n",
      "Epoch: 5/10, Batch: 4, Error: 0.8460776209831238\n",
      "Epoch: 5/10, Batch: 5, Error: 0.7956780195236206\n",
      "Epoch: 5/10, Batch: 6, Error: 0.8065077066421509\n",
      "Epoch: 5/10, Batch: 7, Error: 0.8193915486335754\n",
      "Epoch: 5/10, Batch: 8, Error: 0.51060551404953\n",
      "Epoch: 6/10, Batch: 0, Error: 0.8399630784988403\n",
      "Epoch: 6/10, Batch: 1, Error: 0.674522340297699\n",
      "Epoch: 6/10, Batch: 2, Error: 0.566892683506012\n",
      "Epoch: 6/10, Batch: 3, Error: 0.7164418697357178\n",
      "Epoch: 6/10, Batch: 4, Error: 0.7388321757316589\n",
      "Epoch: 6/10, Batch: 5, Error: 0.715527355670929\n",
      "Epoch: 6/10, Batch: 6, Error: 0.5699841380119324\n",
      "Epoch: 6/10, Batch: 7, Error: 0.5732786059379578\n",
      "Epoch: 6/10, Batch: 8, Error: 0.6875011324882507\n",
      "Epoch: 7/10, Batch: 0, Error: 0.605501651763916\n",
      "Epoch: 7/10, Batch: 1, Error: 0.7228938341140747\n",
      "Epoch: 7/10, Batch: 2, Error: 0.3146432042121887\n",
      "Epoch: 7/10, Batch: 3, Error: 0.7295148372650146\n",
      "Epoch: 7/10, Batch: 4, Error: 0.5547484755516052\n",
      "Epoch: 7/10, Batch: 5, Error: 0.794813871383667\n",
      "Epoch: 7/10, Batch: 6, Error: 0.4896116256713867\n",
      "Epoch: 7/10, Batch: 7, Error: 0.5640860199928284\n",
      "Epoch: 7/10, Batch: 8, Error: 0.6263245940208435\n",
      "Epoch: 8/10, Batch: 0, Error: 0.2781285345554352\n",
      "Epoch: 8/10, Batch: 1, Error: 0.47054654359817505\n",
      "Epoch: 8/10, Batch: 2, Error: 0.5306854248046875\n",
      "Epoch: 8/10, Batch: 3, Error: 0.8751277327537537\n",
      "Epoch: 8/10, Batch: 4, Error: 0.8373952507972717\n",
      "Epoch: 8/10, Batch: 5, Error: 0.6162635684013367\n",
      "Epoch: 8/10, Batch: 6, Error: 0.34485989809036255\n",
      "Epoch: 8/10, Batch: 7, Error: 0.5729241371154785\n",
      "Epoch: 8/10, Batch: 8, Error: 0.41360676288604736\n",
      "Epoch: 9/10, Batch: 0, Error: 0.40834593772888184\n",
      "Epoch: 9/10, Batch: 1, Error: 0.556642472743988\n",
      "Epoch: 9/10, Batch: 2, Error: 0.45212680101394653\n",
      "Epoch: 9/10, Batch: 3, Error: 0.5496556758880615\n",
      "Epoch: 9/10, Batch: 4, Error: 0.5829358100891113\n",
      "Epoch: 9/10, Batch: 5, Error: 0.35472458600997925\n",
      "Epoch: 9/10, Batch: 6, Error: 0.2658121883869171\n",
      "Epoch: 9/10, Batch: 7, Error: 0.6766782402992249\n",
      "Epoch: 9/10, Batch: 8, Error: 0.7143641114234924\n",
      "Epoch: 10/10, Batch: 0, Error: 0.3958888649940491\n",
      "Epoch: 10/10, Batch: 1, Error: 0.5791223049163818\n",
      "Epoch: 10/10, Batch: 2, Error: 0.2931808531284332\n",
      "Epoch: 10/10, Batch: 3, Error: 0.4790355861186981\n",
      "Epoch: 10/10, Batch: 4, Error: 0.3974740505218506\n",
      "Epoch: 10/10, Batch: 5, Error: 0.24293315410614014\n",
      "Epoch: 10/10, Batch: 6, Error: 0.3079981803894043\n",
      "Epoch: 10/10, Batch: 7, Error: 0.3479453921318054\n",
      "Epoch: 10/10, Batch: 8, Error: 0.0682869702577591\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=768, out_features=64, bias=True)\n",
       "  (1): LeakyReLU(negative_slope=0.01)\n",
       "  (2): Dropout(p=0.1, inplace=False)\n",
       "  (3): Linear(in_features=64, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = AdamW(classifier.parameters(), lr=0.001)\n",
    "\n",
    "loss = nn.CrossEntropyLoss()\n",
    "\n",
    "classifier.train()\n",
    "for epoch in range(10):\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        batch = to_device(batch)\n",
    "        labels = batch['labels']\n",
    "        embeddings = embed(**batch)\n",
    "        \n",
    "        classifier.zero_grad()\n",
    "        outputs = classifier(embeddings)\n",
    "        error = loss(outputs, labels)\n",
    "\n",
    "        error.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        print(f'Epoch: {epoch+1}/10, Batch: {i}, Error: {error.item()}')\n",
    "\n",
    "classifier.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9c337fbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.07090286165475845, 2)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    tokens = tokenizer('hello', padding='max_length', truncation=True, return_tensors='pt')\n",
    "    tokens = to_device(tokens)\n",
    "    embeddings = embed(**tokens)\n",
    "    classes = nn.functional.softmax(classifier(embeddings), dim=-1)\n",
    "classes.cpu()[0, 1].item(), torch.argmax(classes).cpu().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c2063ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(classifier, 'classifier.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151bf85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = torch.load('classifier.bin')\n",
    "\n",
    "classifier"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
