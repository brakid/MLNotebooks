{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1bffe87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bibliographic-worcester",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46c9304e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['label', 'text', 'labels'],\n",
       "    num_rows: 33\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LABELS = {\n",
    "    '__label__temperature': 0,\n",
    "    '__label__ethereum': 1,\n",
    "    '__label__help': 2\n",
    "}\n",
    "\n",
    "with open('./utterances.txt', 'r') as data_file:\n",
    "    lines = data_file.readlines()\n",
    "    lines = [ [line.split(' ')[0], ' '.join(line.split(' ')[1:]).replace('\\n', '') ] for line in lines ]\n",
    "    data = pd.DataFrame(lines, columns=['label', 'text'])\n",
    "\n",
    "data['labels'] = data['label'].apply(lambda v: LABELS[v])\n",
    "    \n",
    "dataset = Dataset.from_pandas(data)\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bacf5a85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56ed661c12d14b6fb79e513d7cefca43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7f20ba7ac8>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "def tokenize(records):\n",
    "    return tokenizer(records['text'], padding='max_length', truncation=True)\n",
    "\n",
    "dataset = dataset.map(tokenize, batched=True)\n",
    "dataset = dataset.remove_columns(['text', 'label'])\n",
    "dataset.set_format('torch')\n",
    "\n",
    "dataloader = DataLoader(dataset, shuffle=True, batch_size=4)\n",
    "\n",
    "dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5713b002",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.weight', 'vocab_projector.bias', 'vocab_layer_norm.weight']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DistilBertModel(\n",
       "  (embeddings): Embeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (transformer): Transformer(\n",
       "    (layer): ModuleList(\n",
       "      (0): TransformerBlock(\n",
       "        (attention): MultiHeadSelfAttention(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (ffn): FFN(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (activation): GELUActivation()\n",
       "        )\n",
       "        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (1): TransformerBlock(\n",
       "        (attention): MultiHeadSelfAttention(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (ffn): FFN(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (activation): GELUActivation()\n",
       "        )\n",
       "        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (2): TransformerBlock(\n",
       "        (attention): MultiHeadSelfAttention(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (ffn): FFN(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (activation): GELUActivation()\n",
       "        )\n",
       "        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (3): TransformerBlock(\n",
       "        (attention): MultiHeadSelfAttention(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (ffn): FFN(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (activation): GELUActivation()\n",
       "        )\n",
       "        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (4): TransformerBlock(\n",
       "        (attention): MultiHeadSelfAttention(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (ffn): FFN(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (activation): GELUActivation()\n",
       "        )\n",
       "        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (5): TransformerBlock(\n",
       "        (attention): MultiHeadSelfAttention(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (ffn): FFN(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (activation): GELUActivation()\n",
       "        )\n",
       "        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_model = AutoModel.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "for parameter in embedding_model.parameters():\n",
    "    parameter.requires_grad = False\n",
    "    \n",
    "embedding_model.eval()\n",
    "\n",
    "embedding_model = embedding_model.to(device)\n",
    "\n",
    "def embed(input_ids, attention_mask, labels=None):\n",
    "    with torch.no_grad():\n",
    "        return embedding_model(input_ids=input_ids, attention_mask=attention_mask).last_hidden_state[:, 0, :]\n",
    "\n",
    "embedding_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3f77f95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=768, out_features=64, bias=True)\n",
       "  (1): LeakyReLU(negative_slope=0.01)\n",
       "  (2): Dropout(p=0.1, inplace=False)\n",
       "  (3): Linear(in_features=64, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = nn.Sequential(\n",
    "    nn.Linear(768, 64),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.Dropout(0.1),\n",
    "    nn.Linear(64, 3))\n",
    "\n",
    "classifier = classifier.to(device)\n",
    "\n",
    "classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "checked-photographer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_device(batch):\n",
    "    return {key: value.to(device) for key, value in batch.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9fd0594c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10, Batch: 0, Error: 1.10337495803833\n",
      "Epoch: 1/10, Batch: 1, Error: 1.1484205722808838\n",
      "Epoch: 1/10, Batch: 2, Error: 1.220284342765808\n",
      "Epoch: 1/10, Batch: 3, Error: 1.0381312370300293\n",
      "Epoch: 1/10, Batch: 4, Error: 1.1023352146148682\n",
      "Epoch: 1/10, Batch: 5, Error: 1.0583335161209106\n",
      "Epoch: 1/10, Batch: 6, Error: 1.1577680110931396\n",
      "Epoch: 1/10, Batch: 7, Error: 1.0510632991790771\n",
      "Epoch: 1/10, Batch: 8, Error: 1.0900479555130005\n",
      "Epoch: 2/10, Batch: 0, Error: 0.9846559762954712\n",
      "Epoch: 2/10, Batch: 1, Error: 1.020761251449585\n",
      "Epoch: 2/10, Batch: 2, Error: 1.0099210739135742\n",
      "Epoch: 2/10, Batch: 3, Error: 1.0546566247940063\n",
      "Epoch: 2/10, Batch: 4, Error: 0.9618866443634033\n",
      "Epoch: 2/10, Batch: 5, Error: 0.9502351880073547\n",
      "Epoch: 2/10, Batch: 6, Error: 0.86435467004776\n",
      "Epoch: 2/10, Batch: 7, Error: 1.1874393224716187\n",
      "Epoch: 2/10, Batch: 8, Error: 1.2612329721450806\n",
      "Epoch: 3/10, Batch: 0, Error: 1.2064111232757568\n",
      "Epoch: 3/10, Batch: 1, Error: 0.8983928561210632\n",
      "Epoch: 3/10, Batch: 2, Error: 0.9027181267738342\n",
      "Epoch: 3/10, Batch: 3, Error: 0.889394998550415\n",
      "Epoch: 3/10, Batch: 4, Error: 0.9072856903076172\n",
      "Epoch: 3/10, Batch: 5, Error: 1.0936834812164307\n",
      "Epoch: 3/10, Batch: 6, Error: 0.7551901340484619\n",
      "Epoch: 3/10, Batch: 7, Error: 0.7487297654151917\n",
      "Epoch: 3/10, Batch: 8, Error: 1.2206289768218994\n",
      "Epoch: 4/10, Batch: 0, Error: 1.0288952589035034\n",
      "Epoch: 4/10, Batch: 1, Error: 0.7461867928504944\n",
      "Epoch: 4/10, Batch: 2, Error: 0.838573694229126\n",
      "Epoch: 4/10, Batch: 3, Error: 0.8247872591018677\n",
      "Epoch: 4/10, Batch: 4, Error: 0.8617739677429199\n",
      "Epoch: 4/10, Batch: 5, Error: 0.7379583120346069\n",
      "Epoch: 4/10, Batch: 6, Error: 0.9035772085189819\n",
      "Epoch: 4/10, Batch: 7, Error: 0.993861198425293\n",
      "Epoch: 4/10, Batch: 8, Error: 0.8695749044418335\n",
      "Epoch: 5/10, Batch: 0, Error: 0.7851966619491577\n",
      "Epoch: 5/10, Batch: 1, Error: 0.5946404933929443\n",
      "Epoch: 5/10, Batch: 2, Error: 0.8052685260772705\n",
      "Epoch: 5/10, Batch: 3, Error: 0.6493335962295532\n",
      "Epoch: 5/10, Batch: 4, Error: 0.7356288433074951\n",
      "Epoch: 5/10, Batch: 5, Error: 0.7236701250076294\n",
      "Epoch: 5/10, Batch: 6, Error: 0.5809257626533508\n",
      "Epoch: 5/10, Batch: 7, Error: 0.9551894664764404\n",
      "Epoch: 5/10, Batch: 8, Error: 0.8580610752105713\n",
      "Epoch: 6/10, Batch: 0, Error: 0.7076670527458191\n",
      "Epoch: 6/10, Batch: 1, Error: 0.5757108926773071\n",
      "Epoch: 6/10, Batch: 2, Error: 0.73900306224823\n",
      "Epoch: 6/10, Batch: 3, Error: 0.669243335723877\n",
      "Epoch: 6/10, Batch: 4, Error: 0.6770763397216797\n",
      "Epoch: 6/10, Batch: 5, Error: 0.505289614200592\n",
      "Epoch: 6/10, Batch: 6, Error: 0.5523209571838379\n",
      "Epoch: 6/10, Batch: 7, Error: 0.7737728357315063\n",
      "Epoch: 6/10, Batch: 8, Error: 0.7133690118789673\n",
      "Epoch: 7/10, Batch: 0, Error: 0.702134907245636\n",
      "Epoch: 7/10, Batch: 1, Error: 0.5323696136474609\n",
      "Epoch: 7/10, Batch: 2, Error: 0.637238621711731\n",
      "Epoch: 7/10, Batch: 3, Error: 0.4815608263015747\n",
      "Epoch: 7/10, Batch: 4, Error: 0.5268136262893677\n",
      "Epoch: 7/10, Batch: 5, Error: 0.47538870573043823\n",
      "Epoch: 7/10, Batch: 6, Error: 0.6240885257720947\n",
      "Epoch: 7/10, Batch: 7, Error: 0.5160495042800903\n",
      "Epoch: 7/10, Batch: 8, Error: 0.6162378787994385\n",
      "Epoch: 8/10, Batch: 0, Error: 0.6438782811164856\n",
      "Epoch: 8/10, Batch: 1, Error: 0.6421322822570801\n",
      "Epoch: 8/10, Batch: 2, Error: 0.4974095821380615\n",
      "Epoch: 8/10, Batch: 3, Error: 0.5334122776985168\n",
      "Epoch: 8/10, Batch: 4, Error: 0.527051568031311\n",
      "Epoch: 8/10, Batch: 5, Error: 0.36814239621162415\n",
      "Epoch: 8/10, Batch: 6, Error: 0.3728288412094116\n",
      "Epoch: 8/10, Batch: 7, Error: 0.4126167297363281\n",
      "Epoch: 8/10, Batch: 8, Error: 0.33307144045829773\n",
      "Epoch: 9/10, Batch: 0, Error: 0.544154703617096\n",
      "Epoch: 9/10, Batch: 1, Error: 0.777705192565918\n",
      "Epoch: 9/10, Batch: 2, Error: 0.4191172122955322\n",
      "Epoch: 9/10, Batch: 3, Error: 0.37480825185775757\n",
      "Epoch: 9/10, Batch: 4, Error: 0.3195899426937103\n",
      "Epoch: 9/10, Batch: 5, Error: 0.22063808143138885\n",
      "Epoch: 9/10, Batch: 6, Error: 0.5965402722358704\n",
      "Epoch: 9/10, Batch: 7, Error: 0.44783875346183777\n",
      "Epoch: 9/10, Batch: 8, Error: 0.1721162497997284\n",
      "Epoch: 10/10, Batch: 0, Error: 0.38954421877861023\n",
      "Epoch: 10/10, Batch: 1, Error: 0.2989201247692108\n",
      "Epoch: 10/10, Batch: 2, Error: 0.48507484793663025\n",
      "Epoch: 10/10, Batch: 3, Error: 0.17095500230789185\n",
      "Epoch: 10/10, Batch: 4, Error: 0.22495898604393005\n",
      "Epoch: 10/10, Batch: 5, Error: 0.46010327339172363\n",
      "Epoch: 10/10, Batch: 6, Error: 0.3950765132904053\n",
      "Epoch: 10/10, Batch: 7, Error: 0.6388590335845947\n",
      "Epoch: 10/10, Batch: 8, Error: 0.10095645487308502\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=768, out_features=64, bias=True)\n",
       "  (1): LeakyReLU(negative_slope=0.01)\n",
       "  (2): Dropout(p=0.1, inplace=False)\n",
       "  (3): Linear(in_features=64, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = AdamW(classifier.parameters(), lr=0.001)\n",
    "\n",
    "loss = nn.CrossEntropyLoss()\n",
    "\n",
    "classifier.train()\n",
    "for epoch in range(10):\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        batch = to_device(batch)\n",
    "        labels = batch['labels']\n",
    "        embeddings = embed(**batch)\n",
    "        \n",
    "        classifier.zero_grad()\n",
    "        outputs = classifier(embeddings)\n",
    "        error = loss(outputs, labels)\n",
    "\n",
    "        error.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        print(f'Epoch: {epoch+1}/10, Batch: {i}, Error: {error.item()}')\n",
    "\n",
    "classifier.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c337fbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.4270, 0.3119, 0.2611]]), 0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    tokens = tokenizer('do i need gloves', padding='max_length', truncation=True, return_tensors='pt')\n",
    "    tokens = to_device(tokens)\n",
    "    embeddings = embed(**tokens)\n",
    "    classes = nn.functional.softmax(classifier(embeddings), dim=-1)\n",
    "classes.cpu(), torch.argmax(classes).cpu().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c2063ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(classifier, 'classifier.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151bf85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = torch.load('classifier.bin')\n",
    "\n",
    "classifier"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
