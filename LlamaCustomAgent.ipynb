{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068b82a7-7ce8-4df6-b2f4-663a616b571a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install mlx-lm 'accelerate>=0.26.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26769278-b99f-4283-adfe-fb7cbe4dce29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import litellm\n",
    "from mlx_lm import load, generate\n",
    "\n",
    "class HuggingFaceLLM(litellm.CustomLLM):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        model, tokenizer = load(\"mlx-community/Llama-3.2-3B-Instruct-4bit\")\n",
    "        \n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "    \n",
    "    def completion(self, *args, **kwargs) -> litellm.ModelResponse:\n",
    "        messages = kwargs.get(\"messages\", [])\n",
    "        \n",
    "        prompt = self.tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "        response = generate(self.model, self.tokenizer, prompt=prompt, verbose=False)\n",
    "        print('LLM', messages, response)\n",
    "        \n",
    "        return litellm.completion(\n",
    "            model=\"custom-llm/your-model\",\n",
    "            messages=messages,\n",
    "            mock_response=response,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb29491a-41cc-40c1-8a58-3e884521b2d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07cca5ad4ac04f47b770800194ee0dbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 6 files:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM [{'role': 'user', 'content': 'Hello world!'}] Hello! It's nice to meet you. Is there something I can help you with or would you like to chat?\n",
      "\n",
      "\u001b[1;31mProvider List: https://docs.litellm.ai/docs/providers\u001b[0m\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ModelResponse(id='chatcmpl-8a3b8118-7259-4746-8c9f-902c00f94e2a', created=1735550077, model='your-model', object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content=\"Hello! It's nice to meet you. Is there something I can help you with or would you like to chat?\", role='assistant', tool_calls=None, function_call=None))], usage=Usage(completion_tokens=20, prompt_tokens=10, total_tokens=30, completion_tokens_details=None, prompt_tokens_details=None))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_llm = HuggingFaceLLM()\n",
    "\n",
    "litellm.custom_provider_map = [\n",
    "    {\"provider\": \"custom-llm\", \"custom_handler\": hf_llm}\n",
    "]\n",
    "\n",
    "litellm.completion(\n",
    "    model=\"custom-llm/your-model\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Hello world!\"}]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f0c72c62-41e4-4f52-9b95-49167a7fea7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages=[\n",
    "    { \"role\": \"system\", \"content\": \"\"\"\n",
    "You are an AI assistant specialized in tool-based problem solving. Your expertise lies in analyzing questions to determine whether to use specialized tools or provide direct knowledge-based responses, ensuring optimal resource utilization. If you are lacking information from the user, ask for further information before making a decision. Do not make up any data for your responses but use the provided information only unless it is common knowledge.\n",
    "\n",
    "<documentation>\n",
    "<tools>\n",
    "<tool1>\n",
    "<tool_name>temperature_tool<tool_name>\n",
    "<tool_explanation>For a given location, it provides the current temperature. The location needs to be an actual city name and not a [placeholder value]. Passing a placeholder value will cause an error when calling the tool<tool_explanation>\n",
    "<tool_input_format>{ \"location\": \"[placeholder for the city name]\" }\n",
    "</tool1>\n",
    "<tool2>\n",
    "<tool_name>heating_tool<tool_name>\n",
    "<tool_explanation>For a given roomname, it sets the heater to the specified temperature. The supported room names are 'living room' or 'bedroom'. The response will be a confirmation on whether wsetting the temperature was successful<tool_explanation>\n",
    "<tool_input_format>{ \"room\": \"[placeholder for the room name]\", \"temperature\": [desired temperature] }\n",
    "</tool2>\n",
    "</tools>\n",
    "</documentation>\n",
    "\n",
    "<examples>\n",
    "<example1>\n",
    "Input: \"What's the temperature like in Paris?\"\n",
    "Assistant: <output>\n",
    "<thinking>\n",
    "1. This question requires current temperature data\n",
    "2. We have a temperature tool available\n",
    "3. Direct response without real-time data would be insufficient\n",
    "4. Temperature tool requires a location parameter\n",
    "5. I am not done with the user's question yet as I wait for the tool response to write an answer to the user's question\n",
    "</thinking>\n",
    "<decision>\n",
    "{\n",
    "  \"use_tool\": true, \n",
    "  \"tool\": \"temperature_tool\",\n",
    "  \"tool_input\": {\"location\": \"Paris\"},\n",
    "  \"finished\": false\n",
    "}\n",
    "</decision>\n",
    "</output>\n",
    "</example1>\n",
    "\n",
    "<example2>\n",
    "Inpur from temperature_tool: { \"tool\": \"temperature_tool\", \"tool_input\": {\"location\": \"Paris\"}, \"temperature\": 10.0 }\n",
    "Assistant: <output>\n",
    "<thinking>\n",
    "1. We have received the temperature information for Paris from the temperature_tool\n",
    "2. We do not need to call any tool as we have all information available to answer the user's question for the temperature in Paris\n",
    "3. No real-time data or computation needed\n",
    "4. Can answer directly from provided knowledge\n",
    "5. I do not need further processing steps and I am done answering the user's question\n",
    "</thinking>\n",
    "<decision>\n",
    "{\n",
    "  \"use_tool\": false,\n",
    "  \"response\": \"The temperature is Paris is 10.0 degrees.\",\n",
    "  \"finished\": true\n",
    "}\n",
    "</decision>\n",
    "</output>\n",
    "</example2>\n",
    "\n",
    "<example3>\n",
    "Input: \"What's the temperature at my position?\"\n",
    "Assistant: <output>\n",
    "<thinking>\n",
    "1. This question requires current temperature data\n",
    "2. We have a temperature tool available\n",
    "3. The temperature tool requires a location parameter\n",
    "4. We do not know the user's location. We need to ask for the user's location first. I must not use the temperature tool yet as I do not have all necessary information. I must not use a placeholder value surrounded by [] as tool input\n",
    "5. I am not done with the user's question yet as I require additional user input to process their question\n",
    "</thinking>\n",
    "<decision>\n",
    "{\n",
    "  \"use_tool\": false,\n",
    "  \"question\": \"In order to check the temperature at your location, I need to know your current location. What is you current location?\",\n",
    "  \"finished\": false\n",
    "}\n",
    "</decision>\n",
    "</output>\n",
    "</example3>\n",
    "\n",
    "<example4>\n",
    "Input: \"What's the capital of France?\"\n",
    "Assistant Answer: <output>\n",
    "<thinking>\n",
    "1. This is a factual question\n",
    "2. Information is static and well-known\n",
    "3. No real-time data or computation needed\n",
    "4. Can answer directly from knowledge\n",
    "5. I do not need further processing steps and I am done answering the user's question\n",
    "</thinking>\n",
    "<decision>\n",
    "{\n",
    "  \"use_tool\": false,\n",
    "  \"response\": \"The capital of France is Paris.\",\n",
    "  \"finished\": true\n",
    "}\n",
    "</decision>\n",
    "</output>\n",
    "</example4>\n",
    "\n",
    "<example5>\n",
    "Input: \"Adjust my heater to 15 degrees\"\n",
    "Assistant: <output>\n",
    "<thinking>\n",
    "1. We need to adjust the temperature of a heater\n",
    "2. We have a heating tool available\n",
    "3. The heating tool requires a room parameter and atemperature parameter\n",
    "4. We do not know the room in which to set the temperature. We need to ask for the room name first. I must not use the heating tool yet as I do not have all necessary information. I must not use a placeholder value surrounded by [] as tool input\n",
    "5. I am not done with the user's question yet as I require additional user input to process their question\n",
    "</thinking>\n",
    "<decision>\n",
    "{\n",
    "  \"use_tool\": false,\n",
    "  \"question\": \"In order to set the heating temperature, I need to know in which room to change the temperature. What is the room name in which to set the temperature to 15 degrees?\",\n",
    "  \"finished\": false\n",
    "}\n",
    "</decision>\n",
    "</output>\n",
    "</example5>\n",
    "\n",
    "<example6>\n",
    "Input: \"Adjust the temperature of my bedroom heater\"\n",
    "Assistant: <output>\n",
    "<thinking>\n",
    "1. We need to adjust the temperature of a heater\n",
    "2. We have a heating tool available\n",
    "3. The heating tool requires a room parameter and atemperature parameter\n",
    "4. We do not know the temperature to set the heater to. We need to ask for the target temperature first. I must not use the heating tool yet as I do not have all necessary information. I must not use a placeholder value surrounded by [] as tool input\n",
    "5. I am not done with the user's question yet as I require additional user input to process their question\n",
    "</thinking>\n",
    "<decision>\n",
    "{\n",
    "  \"use_tool\": false,\n",
    "  \"question\": \"In order to set the heating temperature, I need to know the target temperature to set to change the temperature. What is the target temperature for the bedroom heater?\",\n",
    "  \"finished\": false\n",
    "}\n",
    "</decision>\n",
    "</output>\n",
    "</example6>\n",
    "</examples>\n",
    "\n",
    "<instructions>\n",
    "1. Analyze the user's question carefully\n",
    "2. Review available tools and their capabilities, understand what information needs to be passed to each tool and whether this data is available\n",
    "3. Determine if the question requires a tool based on these criteria:\n",
    "   - Needs real-time or dynamic data\n",
    "   - Requires specific computation or processing\n",
    "   - Involves data lookup or API calls\n",
    "   - Cannot be answered with static knowledge\n",
    "4. If a tool is needed:\n",
    "   - Select the most appropriate tool\n",
    "   - Determine whether all information is available to fill in the tool inputs, do not call a tool without having all required information at hand. If I call a tool with a [placeholder] value this will result in an error and I must avoid causing errors\n",
    "   - Format the tool inputs according to the tool's specification, do NOT use values such as \"[user's location]\" or \"[placeholder]\" under any circumstances\n",
    "   - Do not make up the tool's response but wait for the result to be provided back to you\n",
    "   - When using a tool, the processing is not done yet as the tool's response needs to be processed before having completed answering the user's question\n",
    "5. If no tool is needed:\n",
    "   - Provide a direct, informative response\n",
    "   - Processing is finished afterwards\n",
    "6. If further information is required from the user:\n",
    "   - Ask a question for further information that is required to solve the user's problem\n",
    "   - Processing is not finished at this point, as further user input is needed to answer the user's question\n",
    "7. Output your decision in JSON format with either:\n",
    "   - finished: true and use_tool: false and response field\n",
    "   - finished: false and use_tool: false and question field\n",
    "   - finished: false and use_tool: true with tool and tool_input fields\n",
    "   - put your complete response inside the <decision> tag inside the JSON response. Do not put anything outside of this tag.\n",
    "8. Format the response as valid XML content. The reponse should be an XML document with an <output> root tag. Any value outside of this tag will cause an error which we MUST avoid\n",
    "   - the response needs to start with the <output> tag and must close this tag, there must not be any other top-level tag\n",
    "   - there need to be 2 tags inside the <output> root tag: <thinking> for the reasoning and <decision> containing the JSON formatted decision whether to use a tool or not\n",
    "   - do not make up any tool responses. Do not return any more tokens after the </output> closing tag\n",
    "</instructions>\n",
    "\n",
    "<output>\n",
    "<thinking>\n",
    "[Step-by-step analysis of the question and tool requirements, replace with your though process. Be verbose and explain each step of your thinking in depth]\n",
    "</thinking>\n",
    "<decision>\n",
    "{\n",
    "  // One of these three formats:\n",
    "  // Tool usage:\n",
    "  \"use_tool\": true,\n",
    "  \"tool\": \"[selected_tool_name]\",\n",
    "  \"tool_input\": {\n",
    "    // Tool-specific parameters\n",
    "  },\n",
    "  \"finished\": false // when using a tool, finished is always false\n",
    "\n",
    "  // Direct response:\n",
    "  \"use_tool\": false,\n",
    "  \"response\": \"[text response containing the answer to the user's initial question]\",\n",
    "  \"finished\": true // the response contains the answer to the user's question, thus the job is completed\n",
    "\n",
    "  // Ask for further detail:\n",
    "  \"use_tool\": false,\n",
    "  \"question\": \"[question for missing information]\",\n",
    "  \"finished\": false // when asking a question, finished is always false\n",
    "}\n",
    "</decision>\n",
    "</output>\n",
    "\"\"\" },\n",
    "    #{ 'role': 'user', 'content': \"What is the temperature at my location?\" },\n",
    "    #{ 'role': 'user', 'content': \"What is the temperature at my location? I am currently in Neuss.\" },\n",
    "    #{ 'role': 'user', 'content': \"What should I wear when it is 15 degrees outside?\" },\n",
    "    { 'role': 'user', 'content': \"Adjust my heater in the bedroom\" },\n",
    "    { 'role': 'assistant', 'content': \"<output>\" }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e119fd9-55e3-4a9b-8729-424d68d864b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = litellm.completion(\n",
    "    model=\"custom-llm/your-model\",\n",
    "    messages=messages\n",
    ").choices[0].message\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ac5539-7676-46bb-bc0e-dd9ae1dc35be",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages += [\n",
    "    { 'role': response.role, 'content': response.content },\n",
    "    { 'role': 'user', 'content': \"My current location is Luxembourg\" },\n",
    "    { 'role': 'assistant', 'content': \"<output>\" }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb35a633-87b3-4ded-a726-8e4660e6d453",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = litellm.completion(\n",
    "    model=\"custom-llm/your-model\",\n",
    "    messages=messages\n",
    ").choices[0].message\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b500d5ca-6d7a-41ec-a7a2-f60531806b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "messages += [\n",
    "    { 'role': response.role, 'content': response.content }, \n",
    "    #{ 'role': 'user', 'content': json.dumps({ 'tool': 'temperature_tool', \"tool_input\": {\"location\": \"Luxembourg\"}, 'tool_output': { 'temperature': 0.5}}) },\n",
    "    { 'role': 'user', 'content': json.dumps({ 'tool': 'temperature_tool', \"tool_input\": {\"location\": \"Neuss\"}, 'tool_output': { 'temperature': 2}}) },\n",
    "    { 'role': 'assistant', 'content': \"<output>\" }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63a4f2c-cbbb-426b-ad2c-7aa961df8402",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = litellm.completion(\n",
    "    model=\"custom-llm/your-model\",\n",
    "    messages=messages\n",
    ").choices[0].message\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bcc29982-9b58-4479-895b-765e369774ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def temperature_tool(location):\n",
    "    return {'temperature': random.uniform(-5, 20) }\n",
    "\n",
    "def heating_tool(room, temperature):\n",
    "    return {'temperature': temperature, 'successful': True }\n",
    "\n",
    "tools = { 'temperature_tool': temperature_tool, 'heating_tool': heating_tool }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "33cbb0ce-7f67-41e7-82d7-7515c38bff83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "\n",
    "def handle_model(messages):\n",
    "    while True:\n",
    "        response = litellm.completion(\n",
    "            model=\"custom-llm/your-model\",\n",
    "            messages=messages\n",
    "        ).choices[0].message\n",
    "        soup = BeautifulSoup(f'<output>{response.content}', 'xml')\n",
    "        model_response = json.loads(soup.find('decision').text)\n",
    "\n",
    "        if model_response['response']:\n",
    "            print(model_response['response'])\n",
    "            break\n",
    "        elif model_response['question']:\n",
    "            answer = input(model_response['question'])\n",
    "            messages += [\n",
    "                { 'role': response.role, 'content': response.content },\n",
    "                { 'role': 'user', 'content': answer },\n",
    "                { 'role': 'assistant', 'content': \"<output>\" }\n",
    "            ]\n",
    "        elif model_response['use_tool']:\n",
    "            tool_name = model_response['tool']\n",
    "            tool_input = model_response['tool_input']\n",
    "            print(tool_name, tool_input)\n",
    "            tool_output = tools[tool_name](**tool_input)\n",
    "            messages += [\n",
    "                { 'role': response.role, 'content': response.content },\n",
    "                { 'role': 'tool', 'content': json.dumps({ 'tool': tool_name, \"tool_input\": tool_input, 'tool_output': tool_output}) },\n",
    "                { 'role': 'assistant', 'content': \"<output>\" }\n",
    "            ]\n",
    "        else:\n",
    "            print('Invalid state')\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "17af9c05-79aa-4887-b57b-c18a15d30e6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM [{'role': 'system', 'content': '\\nYou are an AI assistant specialized in tool-based problem solving. Your expertise lies in analyzing questions to determine whether to use specialized tools or provide direct knowledge-based responses, ensuring optimal resource utilization. If you are lacking information from the user, ask for further information before making a decision. Do not make up any data for your responses but use the provided information only unless it is common knowledge.\\n\\n<documentation>\\n<tools>\\n<tool1>\\n<tool_name>temperature_tool<tool_name>\\n<tool_explanation>For a given location, it provides the current temperature. The location needs to be an actual city name and not a [placeholder value]. Passing a placeholder value will cause an error when calling the tool<tool_explanation>\\n<tool_input_format>{ \"location\": \"[placeholder for the city name]\" }\\n</tool1>\\n<tool2>\\n<tool_name>heating_tool<tool_name>\\n<tool_explanation>For a given roomname, it sets the heater to the specified temperature. The supported room names are \\'living room\\' or \\'bedroom\\'. The response will be a confirmation on whether wsetting the temperature was successful<tool_explanation>\\n<tool_input_format>{ \"room\": \"[placeholder for the room name]\", \"temperature\": [desired temperature] }\\n</tool2>\\n</tools>\\n</documentation>\\n\\n<examples>\\n<example1>\\nInput: \"What\\'s the temperature like in Paris?\"\\nAssistant: <output>\\n<thinking>\\n1. This question requires current temperature data\\n2. We have a temperature tool available\\n3. Direct response without real-time data would be insufficient\\n4. Temperature tool requires a location parameter\\n5. I am not done with the user\\'s question yet as I wait for the tool response to write an answer to the user\\'s question\\n</thinking>\\n<decision>\\n{\\n  \"use_tool\": true, \\n  \"tool\": \"temperature_tool\",\\n  \"tool_input\": {\"location\": \"Paris\"},\\n  \"finished\": false\\n}\\n</decision>\\n</output>\\n</example1>\\n\\n<example2>\\nInpur from temperature_tool: { \"tool\": \"temperature_tool\", \"tool_input\": {\"location\": \"Paris\"}, \"temperature\": 10.0 }\\nAssistant: <output>\\n<thinking>\\n1. We have received the temperature information for Paris from the temperature_tool\\n2. We do not need to call any tool as we have all information available to answer the user\\'s question for the temperature in Paris\\n3. No real-time data or computation needed\\n4. Can answer directly from provided knowledge\\n5. I do not need further processing steps and I am done answering the user\\'s question\\n</thinking>\\n<decision>\\n{\\n  \"use_tool\": false,\\n  \"response\": \"The temperature is Paris is 10.0 degrees.\",\\n  \"finished\": true\\n}\\n</decision>\\n</output>\\n</example2>\\n\\n<example3>\\nInput: \"What\\'s the temperature at my position?\"\\nAssistant: <output>\\n<thinking>\\n1. This question requires current temperature data\\n2. We have a temperature tool available\\n3. The temperature tool requires a location parameter\\n4. We do not know the user\\'s location. We need to ask for the user\\'s location first. I must not use the temperature tool yet as I do not have all necessary information. I must not use a placeholder value surrounded by [] as tool input\\n5. I am not done with the user\\'s question yet as I require additional user input to process their question\\n</thinking>\\n<decision>\\n{\\n  \"use_tool\": false,\\n  \"question\": \"In order to check the temperature at your location, I need to know your current location. What is you current location?\",\\n  \"finished\": false\\n}\\n</decision>\\n</output>\\n</example3>\\n\\n<example4>\\nInput: \"What\\'s the capital of France?\"\\nAssistant Answer: <output>\\n<thinking>\\n1. This is a factual question\\n2. Information is static and well-known\\n3. No real-time data or computation needed\\n4. Can answer directly from knowledge\\n5. I do not need further processing steps and I am done answering the user\\'s question\\n</thinking>\\n<decision>\\n{\\n  \"use_tool\": false,\\n  \"response\": \"The capital of France is Paris.\",\\n  \"finished\": true\\n}\\n</decision>\\n</output>\\n</example4>\\n\\n<example5>\\nInput: \"Adjust my heater to 15 degrees\"\\nAssistant: <output>\\n<thinking>\\n1. We need to adjust the temperature of a heater\\n2. We have a heating tool available\\n3. The heating tool requires a room parameter and atemperature parameter\\n4. We do not know the room in which to set the temperature. We need to ask for the room name first. I must not use the heating tool yet as I do not have all necessary information. I must not use a placeholder value surrounded by [] as tool input\\n5. I am not done with the user\\'s question yet as I require additional user input to process their question\\n</thinking>\\n<decision>\\n{\\n  \"use_tool\": false,\\n  \"question\": \"In order to set the heating temperature, I need to know in which room to change the temperature. What is the room name in which to set the temperature to 15 degrees?\",\\n  \"finished\": false\\n}\\n</decision>\\n</output>\\n</example5>\\n\\n<example6>\\nInput: \"Adjust the temperature of my bedroom heater\"\\nAssistant: <output>\\n<thinking>\\n1. We need to adjust the temperature of a heater\\n2. We have a heating tool available\\n3. The heating tool requires a room parameter and atemperature parameter\\n4. We do not know the temperature to set the heater to. We need to ask for the target temperature first. I must not use the heating tool yet as I do not have all necessary information. I must not use a placeholder value surrounded by [] as tool input\\n5. I am not done with the user\\'s question yet as I require additional user input to process their question\\n</thinking>\\n<decision>\\n{\\n  \"use_tool\": false,\\n  \"question\": \"In order to set the heating temperature, I need to know the target temperature to set to change the temperature. What is the target temperature for the bedroom heater?\",\\n  \"finished\": false\\n}\\n</decision>\\n</output>\\n</example6>\\n</examples>\\n\\n<instructions>\\n1. Analyze the user\\'s question carefully\\n2. Review available tools and their capabilities, understand what information needs to be passed to each tool and whether this data is available\\n3. Determine if the question requires a tool based on these criteria:\\n   - Needs real-time or dynamic data\\n   - Requires specific computation or processing\\n   - Involves data lookup or API calls\\n   - Cannot be answered with static knowledge\\n4. If a tool is needed:\\n   - Select the most appropriate tool\\n   - Determine whether all information is available to fill in the tool inputs, do not call a tool without having all required information at hand. If I call a tool with a [placeholder] value this will result in an error and I must avoid causing errors\\n   - Format the tool inputs according to the tool\\'s specification, do NOT use values such as \"[user\\'s location]\" or \"[placeholder]\" under any circumstances\\n   - Do not make up the tool\\'s response but wait for the result to be provided back to you\\n   - When using a tool, the processing is not done yet as the tool\\'s response needs to be processed before having completed answering the user\\'s question\\n5. If no tool is needed:\\n   - Provide a direct, informative response\\n   - Processing is finished afterwards\\n6. If further information is required from the user:\\n   - Ask a question for further information that is required to solve the user\\'s problem\\n   - Processing is not finished at this point, as further user input is needed to answer the user\\'s question\\n7. Output your decision in JSON format with either:\\n   - finished: true and use_tool: false and response field\\n   - finished: false and use_tool: false and question field\\n   - finished: false and use_tool: true with tool and tool_input fields\\n   - put your complete response inside the <decision> tag inside the JSON response. Do not put anything outside of this tag.\\n8. Format the response as valid XML content. The reponse should be an XML document with an <output> root tag. Any value outside of this tag will cause an error which we MUST avoid\\n   - the response needs to start with the <output> tag and must close this tag, there must not be any other top-level tag\\n   - there need to be 2 tags inside the <output> root tag: <thinking> for the reasoning and <decision> containing the JSON formatted decision whether to use a tool or not\\n   - do not make up any tool responses. Do not return any more tokens after the </output> closing tag\\n</instructions>\\n\\n<output>\\n<thinking>\\n[Step-by-step analysis of the question and tool requirements, replace with your though process. Be verbose and explain each step of your thinking in depth]\\n</thinking>\\n<decision>\\n{\\n  // One of these three formats:\\n  // Tool usage:\\n  \"use_tool\": true,\\n  \"tool\": \"[selected_tool_name]\",\\n  \"tool_input\": {\\n    // Tool-specific parameters\\n  },\\n  \"finished\": false // when using a tool, finished is always false\\n\\n  // Direct response:\\n  \"use_tool\": false,\\n  \"response\": \"[text response containing the answer to the user\\'s initial question]\",\\n  \"finished\": true // the response contains the answer to the user\\'s question, thus the job is completed\\n\\n  // Ask for further detail:\\n  \"use_tool\": false,\\n  \"question\": \"[question for missing information]\",\\n  \"finished\": false // when asking a question, finished is always false\\n}\\n</decision>\\n</output>\\n'}, {'role': 'user', 'content': 'Adjust my heater in the bedroom'}, {'role': 'assistant', 'content': '<output>'}] <thinking>\n",
      "1. This question requires adjusting the temperature of a heater\n",
      "2. We have a heating tool available\n",
      "3. The heating tool requires a room parameter and a temperature parameter\n",
      "4. We do not know the temperature to set the heater to. We need to ask for the target temperature first. I must not use the heating tool yet as I do not have all necessary information. I must not use a placeholder value surrounded by [] as tool input\n",
      "5. I am not done with the user's question yet as I require additional user input to process their question\n",
      "</thinking>\n",
      "<decision>\n",
      "{\n",
      "  \"use_tool\": false,\n",
      "  \"question\": \"In order to set the heating temperature, I need to know the target temperature to set to change the temperature. What is the target temperature for the bedroom heater?\",\n",
      "  \"finished\": false\n",
      "}\n",
      "</decision>\n",
      "</output>\n",
      "\n",
      "\u001b[1;31mProvider List: https://docs.litellm.ai/docs/providers\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "In order to set the heating temperature, I need to know the target temperature to set to change the temperature. What is the target temperature for the bedroom heater? 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM [{'role': 'system', 'content': '\\nYou are an AI assistant specialized in tool-based problem solving. Your expertise lies in analyzing questions to determine whether to use specialized tools or provide direct knowledge-based responses, ensuring optimal resource utilization. If you are lacking information from the user, ask for further information before making a decision. Do not make up any data for your responses but use the provided information only unless it is common knowledge.\\n\\n<documentation>\\n<tools>\\n<tool1>\\n<tool_name>temperature_tool<tool_name>\\n<tool_explanation>For a given location, it provides the current temperature. The location needs to be an actual city name and not a [placeholder value]. Passing a placeholder value will cause an error when calling the tool<tool_explanation>\\n<tool_input_format>{ \"location\": \"[placeholder for the city name]\" }\\n</tool1>\\n<tool2>\\n<tool_name>heating_tool<tool_name>\\n<tool_explanation>For a given roomname, it sets the heater to the specified temperature. The supported room names are \\'living room\\' or \\'bedroom\\'. The response will be a confirmation on whether wsetting the temperature was successful<tool_explanation>\\n<tool_input_format>{ \"room\": \"[placeholder for the room name]\", \"temperature\": [desired temperature] }\\n</tool2>\\n</tools>\\n</documentation>\\n\\n<examples>\\n<example1>\\nInput: \"What\\'s the temperature like in Paris?\"\\nAssistant: <output>\\n<thinking>\\n1. This question requires current temperature data\\n2. We have a temperature tool available\\n3. Direct response without real-time data would be insufficient\\n4. Temperature tool requires a location parameter\\n5. I am not done with the user\\'s question yet as I wait for the tool response to write an answer to the user\\'s question\\n</thinking>\\n<decision>\\n{\\n  \"use_tool\": true, \\n  \"tool\": \"temperature_tool\",\\n  \"tool_input\": {\"location\": \"Paris\"},\\n  \"finished\": false\\n}\\n</decision>\\n</output>\\n</example1>\\n\\n<example2>\\nInpur from temperature_tool: { \"tool\": \"temperature_tool\", \"tool_input\": {\"location\": \"Paris\"}, \"temperature\": 10.0 }\\nAssistant: <output>\\n<thinking>\\n1. We have received the temperature information for Paris from the temperature_tool\\n2. We do not need to call any tool as we have all information available to answer the user\\'s question for the temperature in Paris\\n3. No real-time data or computation needed\\n4. Can answer directly from provided knowledge\\n5. I do not need further processing steps and I am done answering the user\\'s question\\n</thinking>\\n<decision>\\n{\\n  \"use_tool\": false,\\n  \"response\": \"The temperature is Paris is 10.0 degrees.\",\\n  \"finished\": true\\n}\\n</decision>\\n</output>\\n</example2>\\n\\n<example3>\\nInput: \"What\\'s the temperature at my position?\"\\nAssistant: <output>\\n<thinking>\\n1. This question requires current temperature data\\n2. We have a temperature tool available\\n3. The temperature tool requires a location parameter\\n4. We do not know the user\\'s location. We need to ask for the user\\'s location first. I must not use the temperature tool yet as I do not have all necessary information. I must not use a placeholder value surrounded by [] as tool input\\n5. I am not done with the user\\'s question yet as I require additional user input to process their question\\n</thinking>\\n<decision>\\n{\\n  \"use_tool\": false,\\n  \"question\": \"In order to check the temperature at your location, I need to know your current location. What is you current location?\",\\n  \"finished\": false\\n}\\n</decision>\\n</output>\\n</example3>\\n\\n<example4>\\nInput: \"What\\'s the capital of France?\"\\nAssistant Answer: <output>\\n<thinking>\\n1. This is a factual question\\n2. Information is static and well-known\\n3. No real-time data or computation needed\\n4. Can answer directly from knowledge\\n5. I do not need further processing steps and I am done answering the user\\'s question\\n</thinking>\\n<decision>\\n{\\n  \"use_tool\": false,\\n  \"response\": \"The capital of France is Paris.\",\\n  \"finished\": true\\n}\\n</decision>\\n</output>\\n</example4>\\n\\n<example5>\\nInput: \"Adjust my heater to 15 degrees\"\\nAssistant: <output>\\n<thinking>\\n1. We need to adjust the temperature of a heater\\n2. We have a heating tool available\\n3. The heating tool requires a room parameter and atemperature parameter\\n4. We do not know the room in which to set the temperature. We need to ask for the room name first. I must not use the heating tool yet as I do not have all necessary information. I must not use a placeholder value surrounded by [] as tool input\\n5. I am not done with the user\\'s question yet as I require additional user input to process their question\\n</thinking>\\n<decision>\\n{\\n  \"use_tool\": false,\\n  \"question\": \"In order to set the heating temperature, I need to know in which room to change the temperature. What is the room name in which to set the temperature to 15 degrees?\",\\n  \"finished\": false\\n}\\n</decision>\\n</output>\\n</example5>\\n\\n<example6>\\nInput: \"Adjust the temperature of my bedroom heater\"\\nAssistant: <output>\\n<thinking>\\n1. We need to adjust the temperature of a heater\\n2. We have a heating tool available\\n3. The heating tool requires a room parameter and atemperature parameter\\n4. We do not know the temperature to set the heater to. We need to ask for the target temperature first. I must not use the heating tool yet as I do not have all necessary information. I must not use a placeholder value surrounded by [] as tool input\\n5. I am not done with the user\\'s question yet as I require additional user input to process their question\\n</thinking>\\n<decision>\\n{\\n  \"use_tool\": false,\\n  \"question\": \"In order to set the heating temperature, I need to know the target temperature to set to change the temperature. What is the target temperature for the bedroom heater?\",\\n  \"finished\": false\\n}\\n</decision>\\n</output>\\n</example6>\\n</examples>\\n\\n<instructions>\\n1. Analyze the user\\'s question carefully\\n2. Review available tools and their capabilities, understand what information needs to be passed to each tool and whether this data is available\\n3. Determine if the question requires a tool based on these criteria:\\n   - Needs real-time or dynamic data\\n   - Requires specific computation or processing\\n   - Involves data lookup or API calls\\n   - Cannot be answered with static knowledge\\n4. If a tool is needed:\\n   - Select the most appropriate tool\\n   - Determine whether all information is available to fill in the tool inputs, do not call a tool without having all required information at hand. If I call a tool with a [placeholder] value this will result in an error and I must avoid causing errors\\n   - Format the tool inputs according to the tool\\'s specification, do NOT use values such as \"[user\\'s location]\" or \"[placeholder]\" under any circumstances\\n   - Do not make up the tool\\'s response but wait for the result to be provided back to you\\n   - When using a tool, the processing is not done yet as the tool\\'s response needs to be processed before having completed answering the user\\'s question\\n5. If no tool is needed:\\n   - Provide a direct, informative response\\n   - Processing is finished afterwards\\n6. If further information is required from the user:\\n   - Ask a question for further information that is required to solve the user\\'s problem\\n   - Processing is not finished at this point, as further user input is needed to answer the user\\'s question\\n7. Output your decision in JSON format with either:\\n   - finished: true and use_tool: false and response field\\n   - finished: false and use_tool: false and question field\\n   - finished: false and use_tool: true with tool and tool_input fields\\n   - put your complete response inside the <decision> tag inside the JSON response. Do not put anything outside of this tag.\\n8. Format the response as valid XML content. The reponse should be an XML document with an <output> root tag. Any value outside of this tag will cause an error which we MUST avoid\\n   - the response needs to start with the <output> tag and must close this tag, there must not be any other top-level tag\\n   - there need to be 2 tags inside the <output> root tag: <thinking> for the reasoning and <decision> containing the JSON formatted decision whether to use a tool or not\\n   - do not make up any tool responses. Do not return any more tokens after the </output> closing tag\\n</instructions>\\n\\n<output>\\n<thinking>\\n[Step-by-step analysis of the question and tool requirements, replace with your though process. Be verbose and explain each step of your thinking in depth]\\n</thinking>\\n<decision>\\n{\\n  // One of these three formats:\\n  // Tool usage:\\n  \"use_tool\": true,\\n  \"tool\": \"[selected_tool_name]\",\\n  \"tool_input\": {\\n    // Tool-specific parameters\\n  },\\n  \"finished\": false // when using a tool, finished is always false\\n\\n  // Direct response:\\n  \"use_tool\": false,\\n  \"response\": \"[text response containing the answer to the user\\'s initial question]\",\\n  \"finished\": true // the response contains the answer to the user\\'s question, thus the job is completed\\n\\n  // Ask for further detail:\\n  \"use_tool\": false,\\n  \"question\": \"[question for missing information]\",\\n  \"finished\": false // when asking a question, finished is always false\\n}\\n</decision>\\n</output>\\n'}, {'role': 'user', 'content': 'Adjust my heater in the bedroom'}, {'role': 'assistant', 'content': '<output>'}, {'role': 'assistant', 'content': '<thinking>\\n1. This question requires adjusting the temperature of a heater\\n2. We have a heating tool available\\n3. The heating tool requires a room parameter and a temperature parameter\\n4. We do not know the temperature to set the heater to. We need to ask for the target temperature first. I must not use the heating tool yet as I do not have all necessary information. I must not use a placeholder value surrounded by [] as tool input\\n5. I am not done with the user\\'s question yet as I require additional user input to process their question\\n</thinking>\\n<decision>\\n{\\n  \"use_tool\": false,\\n  \"question\": \"In order to set the heating temperature, I need to know the target temperature to set to change the temperature. What is the target temperature for the bedroom heater?\",\\n  \"finished\": false\\n}\\n</decision>\\n</output>'}, {'role': 'user', 'content': '16'}, {'role': 'assistant', 'content': '<output>'}] <thinking>\n",
      "1. We have received the target temperature to set the heater to 16 degrees\n",
      "2. We have a heating tool available\n",
      "3. The heating tool requires a room parameter and a temperature parameter\n",
      "4. We know the room in which to set the temperature, which is the bedroom\n",
      "5. We can now use the heating tool to adjust the temperature\n",
      "6. The heating tool will return a confirmation on whether the temperature was set successfully\n",
      "7. We will process the response from the heating tool and provide the result to the user\n",
      "8. After processing the response, we will have the final answer to the user's question\n",
      "9. We can now output the final answer to the user\n",
      "</thinking>\n",
      "<decision>\n",
      "{\n",
      "  \"use_tool\": true,\n",
      "  \"tool\": \"heating_tool\",\n",
      "  \"tool_input\": {\"room\": \"bedroom\", \"temperature\": 16.0},\n",
      "  \"finished\": true\n",
      "}\n",
      "</decision>\n",
      "</output>\n",
      "\n",
      "\u001b[1;31mProvider List: https://docs.litellm.ai/docs/providers\u001b[0m\n",
      "\n",
      "heating_tool {'room': 'bedroom', 'temperature': 16.0}\n",
      "LLM [{'role': 'system', 'content': '\\nYou are an AI assistant specialized in tool-based problem solving. Your expertise lies in analyzing questions to determine whether to use specialized tools or provide direct knowledge-based responses, ensuring optimal resource utilization. If you are lacking information from the user, ask for further information before making a decision. Do not make up any data for your responses but use the provided information only unless it is common knowledge.\\n\\n<documentation>\\n<tools>\\n<tool1>\\n<tool_name>temperature_tool<tool_name>\\n<tool_explanation>For a given location, it provides the current temperature. The location needs to be an actual city name and not a [placeholder value]. Passing a placeholder value will cause an error when calling the tool<tool_explanation>\\n<tool_input_format>{ \"location\": \"[placeholder for the city name]\" }\\n</tool1>\\n<tool2>\\n<tool_name>heating_tool<tool_name>\\n<tool_explanation>For a given roomname, it sets the heater to the specified temperature. The supported room names are \\'living room\\' or \\'bedroom\\'. The response will be a confirmation on whether wsetting the temperature was successful<tool_explanation>\\n<tool_input_format>{ \"room\": \"[placeholder for the room name]\", \"temperature\": [desired temperature] }\\n</tool2>\\n</tools>\\n</documentation>\\n\\n<examples>\\n<example1>\\nInput: \"What\\'s the temperature like in Paris?\"\\nAssistant: <output>\\n<thinking>\\n1. This question requires current temperature data\\n2. We have a temperature tool available\\n3. Direct response without real-time data would be insufficient\\n4. Temperature tool requires a location parameter\\n5. I am not done with the user\\'s question yet as I wait for the tool response to write an answer to the user\\'s question\\n</thinking>\\n<decision>\\n{\\n  \"use_tool\": true, \\n  \"tool\": \"temperature_tool\",\\n  \"tool_input\": {\"location\": \"Paris\"},\\n  \"finished\": false\\n}\\n</decision>\\n</output>\\n</example1>\\n\\n<example2>\\nInpur from temperature_tool: { \"tool\": \"temperature_tool\", \"tool_input\": {\"location\": \"Paris\"}, \"temperature\": 10.0 }\\nAssistant: <output>\\n<thinking>\\n1. We have received the temperature information for Paris from the temperature_tool\\n2. We do not need to call any tool as we have all information available to answer the user\\'s question for the temperature in Paris\\n3. No real-time data or computation needed\\n4. Can answer directly from provided knowledge\\n5. I do not need further processing steps and I am done answering the user\\'s question\\n</thinking>\\n<decision>\\n{\\n  \"use_tool\": false,\\n  \"response\": \"The temperature is Paris is 10.0 degrees.\",\\n  \"finished\": true\\n}\\n</decision>\\n</output>\\n</example2>\\n\\n<example3>\\nInput: \"What\\'s the temperature at my position?\"\\nAssistant: <output>\\n<thinking>\\n1. This question requires current temperature data\\n2. We have a temperature tool available\\n3. The temperature tool requires a location parameter\\n4. We do not know the user\\'s location. We need to ask for the user\\'s location first. I must not use the temperature tool yet as I do not have all necessary information. I must not use a placeholder value surrounded by [] as tool input\\n5. I am not done with the user\\'s question yet as I require additional user input to process their question\\n</thinking>\\n<decision>\\n{\\n  \"use_tool\": false,\\n  \"question\": \"In order to check the temperature at your location, I need to know your current location. What is you current location?\",\\n  \"finished\": false\\n}\\n</decision>\\n</output>\\n</example3>\\n\\n<example4>\\nInput: \"What\\'s the capital of France?\"\\nAssistant Answer: <output>\\n<thinking>\\n1. This is a factual question\\n2. Information is static and well-known\\n3. No real-time data or computation needed\\n4. Can answer directly from knowledge\\n5. I do not need further processing steps and I am done answering the user\\'s question\\n</thinking>\\n<decision>\\n{\\n  \"use_tool\": false,\\n  \"response\": \"The capital of France is Paris.\",\\n  \"finished\": true\\n}\\n</decision>\\n</output>\\n</example4>\\n\\n<example5>\\nInput: \"Adjust my heater to 15 degrees\"\\nAssistant: <output>\\n<thinking>\\n1. We need to adjust the temperature of a heater\\n2. We have a heating tool available\\n3. The heating tool requires a room parameter and atemperature parameter\\n4. We do not know the room in which to set the temperature. We need to ask for the room name first. I must not use the heating tool yet as I do not have all necessary information. I must not use a placeholder value surrounded by [] as tool input\\n5. I am not done with the user\\'s question yet as I require additional user input to process their question\\n</thinking>\\n<decision>\\n{\\n  \"use_tool\": false,\\n  \"question\": \"In order to set the heating temperature, I need to know in which room to change the temperature. What is the room name in which to set the temperature to 15 degrees?\",\\n  \"finished\": false\\n}\\n</decision>\\n</output>\\n</example5>\\n\\n<example6>\\nInput: \"Adjust the temperature of my bedroom heater\"\\nAssistant: <output>\\n<thinking>\\n1. We need to adjust the temperature of a heater\\n2. We have a heating tool available\\n3. The heating tool requires a room parameter and atemperature parameter\\n4. We do not know the temperature to set the heater to. We need to ask for the target temperature first. I must not use the heating tool yet as I do not have all necessary information. I must not use a placeholder value surrounded by [] as tool input\\n5. I am not done with the user\\'s question yet as I require additional user input to process their question\\n</thinking>\\n<decision>\\n{\\n  \"use_tool\": false,\\n  \"question\": \"In order to set the heating temperature, I need to know the target temperature to set to change the temperature. What is the target temperature for the bedroom heater?\",\\n  \"finished\": false\\n}\\n</decision>\\n</output>\\n</example6>\\n</examples>\\n\\n<instructions>\\n1. Analyze the user\\'s question carefully\\n2. Review available tools and their capabilities, understand what information needs to be passed to each tool and whether this data is available\\n3. Determine if the question requires a tool based on these criteria:\\n   - Needs real-time or dynamic data\\n   - Requires specific computation or processing\\n   - Involves data lookup or API calls\\n   - Cannot be answered with static knowledge\\n4. If a tool is needed:\\n   - Select the most appropriate tool\\n   - Determine whether all information is available to fill in the tool inputs, do not call a tool without having all required information at hand. If I call a tool with a [placeholder] value this will result in an error and I must avoid causing errors\\n   - Format the tool inputs according to the tool\\'s specification, do NOT use values such as \"[user\\'s location]\" or \"[placeholder]\" under any circumstances\\n   - Do not make up the tool\\'s response but wait for the result to be provided back to you\\n   - When using a tool, the processing is not done yet as the tool\\'s response needs to be processed before having completed answering the user\\'s question\\n5. If no tool is needed:\\n   - Provide a direct, informative response\\n   - Processing is finished afterwards\\n6. If further information is required from the user:\\n   - Ask a question for further information that is required to solve the user\\'s problem\\n   - Processing is not finished at this point, as further user input is needed to answer the user\\'s question\\n7. Output your decision in JSON format with either:\\n   - finished: true and use_tool: false and response field\\n   - finished: false and use_tool: false and question field\\n   - finished: false and use_tool: true with tool and tool_input fields\\n   - put your complete response inside the <decision> tag inside the JSON response. Do not put anything outside of this tag.\\n8. Format the response as valid XML content. The reponse should be an XML document with an <output> root tag. Any value outside of this tag will cause an error which we MUST avoid\\n   - the response needs to start with the <output> tag and must close this tag, there must not be any other top-level tag\\n   - there need to be 2 tags inside the <output> root tag: <thinking> for the reasoning and <decision> containing the JSON formatted decision whether to use a tool or not\\n   - do not make up any tool responses. Do not return any more tokens after the </output> closing tag\\n</instructions>\\n\\n<output>\\n<thinking>\\n[Step-by-step analysis of the question and tool requirements, replace with your though process. Be verbose and explain each step of your thinking in depth]\\n</thinking>\\n<decision>\\n{\\n  // One of these three formats:\\n  // Tool usage:\\n  \"use_tool\": true,\\n  \"tool\": \"[selected_tool_name]\",\\n  \"tool_input\": {\\n    // Tool-specific parameters\\n  },\\n  \"finished\": false // when using a tool, finished is always false\\n\\n  // Direct response:\\n  \"use_tool\": false,\\n  \"response\": \"[text response containing the answer to the user\\'s initial question]\",\\n  \"finished\": true // the response contains the answer to the user\\'s question, thus the job is completed\\n\\n  // Ask for further detail:\\n  \"use_tool\": false,\\n  \"question\": \"[question for missing information]\",\\n  \"finished\": false // when asking a question, finished is always false\\n}\\n</decision>\\n</output>\\n'}, {'role': 'user', 'content': 'Adjust my heater in the bedroom'}, {'role': 'assistant', 'content': '<output>'}, {'role': 'assistant', 'content': '<thinking>\\n1. This question requires adjusting the temperature of a heater\\n2. We have a heating tool available\\n3. The heating tool requires a room parameter and a temperature parameter\\n4. We do not know the temperature to set the heater to. We need to ask for the target temperature first. I must not use the heating tool yet as I do not have all necessary information. I must not use a placeholder value surrounded by [] as tool input\\n5. I am not done with the user\\'s question yet as I require additional user input to process their question\\n</thinking>\\n<decision>\\n{\\n  \"use_tool\": false,\\n  \"question\": \"In order to set the heating temperature, I need to know the target temperature to set to change the temperature. What is the target temperature for the bedroom heater?\",\\n  \"finished\": false\\n}\\n</decision>\\n</output>'}, {'role': 'user', 'content': '16'}, {'role': 'assistant', 'content': '<output>'}, {'role': 'assistant', 'content': '<thinking>\\n1. We have received the target temperature to set the heater to 16 degrees\\n2. We have a heating tool available\\n3. The heating tool requires a room parameter and a temperature parameter\\n4. We know the room in which to set the temperature, which is the bedroom\\n5. We can now use the heating tool to adjust the temperature\\n6. The heating tool will return a confirmation on whether the temperature was set successfully\\n7. We will process the response from the heating tool and provide the result to the user\\n8. After processing the response, we will have the final answer to the user\\'s question\\n9. We can now output the final answer to the user\\n</thinking>\\n<decision>\\n{\\n  \"use_tool\": true,\\n  \"tool\": \"heating_tool\",\\n  \"tool_input\": {\"room\": \"bedroom\", \"temperature\": 16.0},\\n  \"finished\": true\\n}\\n</decision>\\n</output>'}, {'role': 'tool', 'content': '{\"tool\": \"heating_tool\", \"tool_input\": {\"room\": \"bedroom\", \"temperature\": 16.0}, \"tool_output\": {\"temperature\": 16.0, \"successful\": true}}'}, {'role': 'assistant', 'content': '<output>'}] <thinking>\n",
      "1. We have received the output from the heating tool\n",
      "2. The heating tool confirmed that the temperature was set successfully to 16 degrees\n",
      "3. We can now provide the final answer to the user\n",
      "4. The final answer is the confirmation from the heating tool\n",
      "5. We do not need to use any other tools to answer the user's question\n",
      "6. The user's question has been fully answered\n",
      "7. We can now output the final answer to the user\n",
      "</thinking>\n",
      "<decision>\n",
      "{\n",
      "  \"use_tool\": false,\n",
      "  \"response\": \"The temperature in the bedroom has been set to 16 degrees.\",\n",
      "  \"finished\": true\n",
      "}\n",
      "</decision>\n",
      "</output>\n",
      "\n",
      "\u001b[1;31mProvider List: https://docs.litellm.ai/docs/providers\u001b[0m\n",
      "\n",
      "The temperature in the bedroom has been set to 16 degrees.\n"
     ]
    }
   ],
   "source": [
    "handle_model(messages)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
