{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0bd4917-2952-4f78-baba-82d643fe5e4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db02dfb745264760b5c87ad54cba0b60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 10 files:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from mlx_lm import load, generate\n",
    "import datetime\n",
    "import random\n",
    "\n",
    "model, tokenizer = load(\"mlx-community/Qwen2.5-14B-Instruct-1M-4bit\") #mlx-community/Qwen2.5-7B-Instruct-1M-4bit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0e12659-c3bd-4c66-a7b8-0b20519ed4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def temperature_tool(location: str):\n",
    "    \"\"\"\n",
    "    The tool provides the current temperature for a given location (city name). The location needs to be an actual city name and not a [placeholder value]\n",
    "    \n",
    "    Args:\n",
    "        location: The name of the city whose temperature to obtain\n",
    "    Returns:\n",
    "        The temperature of the requested city\n",
    "    \"\"\"\n",
    "    return random.uniform(-5, 20)\n",
    "\n",
    "def heating_tool(room: str, temperature: float):\n",
    "    \"\"\"\n",
    "    The tool sets the temperature for a given roomname. The response is an indication whether the change of temperature was successful or not\n",
    "    \n",
    "    Args:\n",
    "        room: The name of the room where to set the temperature\n",
    "        temperature: The desired temperature in degree celsius\n",
    "    Returns:\n",
    "        a boolean indicating whether setting the temperature was succesfull or not\n",
    "    \"\"\"\n",
    "    return { 'temperature': temperature, 'room': room, 'temperature_changed_successfully': True }\n",
    "\n",
    "def current_time():\n",
    "    \"\"\"Get the current local time as a string.\"\"\"\n",
    "    return str(datetime.now())\n",
    "\n",
    "tools = [temperature_tool, heating_tool, current_time]\n",
    "tools_dict = {\n",
    "    'temperature_tool': temperature_tool,\n",
    "    'heating_tool': heating_tool,\n",
    "    'current_time': current_time\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd64eb68-5ab3-4e47-aa82-092c83fd7e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"\"\"\n",
    "    You are an AI assistant specialized in tool-based problem solving. \n",
    "    Your expertise lies in analyzing questions to determine whether to use specialized tools or provide direct knowledge-based responses, \n",
    "    ensuring optimal resource utilization. If you are lacking information from the user, ask for further information before making a decision. \n",
    "    Never make up any data for your responses but use the provided information only unless it is common knowledge.\n",
    "    Never fill in missing data you need from the customer unless explicitly being asked for it.\n",
    "    Format your response as XML with the following format:\n",
    "    <answer>\n",
    "     <response>[your answer or question or tool invocation]</response>\n",
    "     <tool_call>[if applicable: what tool to call and with which parameters]</tool_call>\n",
    "     <completed>[true is the conversation is done, or false if further customer responses are needed]</completed>\n",
    "    </answer>\n",
    "    \"\"\"},\n",
    "    {\"role\": \"user\", \"content\": \"what is the current temperature?\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce894fc8-6c31-4228-9b97-3413d23e351b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "\n",
    "def handle_model(messages):\n",
    "    while True:\n",
    "        messages.append({\"role\": \"assistant\", \"content\": \"<answer>\"})\n",
    "        prompt = tokenizer.apply_chat_template(\n",
    "            messages, add_generation_prompt=False, tools=tools, continue_final_message=True\n",
    "        )\n",
    "        response = generate(model, tokenizer, prompt=prompt, verbose=True)\n",
    "        soup = BeautifulSoup(f'<answer>{response}', 'xml')\n",
    "        soup = soup.find('answer')\n",
    "        print(soup)\n",
    "        is_done = (soup.find('completed').text == 'true')\n",
    "        print(soup.find('response').text)\n",
    "        messages[-1]['content'] += response\n",
    "\n",
    "        if is_done:\n",
    "            break\n",
    "        else:\n",
    "            if soup.find('tool_call'):\n",
    "                tool_call = json.loads(soup.find('tool_call').text)\n",
    "                tool_output = tools_dict[tool_call['name']](**tool_call['arguments'])\n",
    "\n",
    "                messages.append({\"role\": \"tool\", \"name\": tool_call['name'], \"content\": str(tool_output)})\n",
    "            else:\n",
    "                answer = input()\n",
    "            messages.append({\"role\": \"user\", \"content\": answer })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2f295f1-fbea-4469-8988-b0cd73564f1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========\n",
      "\n",
      " <response>To provide you with the current temperature, I need to know the name of the city you are interested in.</response> \n",
      " <completed>false</completed> \n",
      "</answer>\n",
      "==========\n",
      "Prompt: 526 tokens, 101.800 tokens-per-sec\n",
      "Generation: 39 tokens, 10.030 tokens-per-sec\n",
      "Peak memory: 8.694 GB\n",
      "<answer>\n",
      "<response>To provide you with the current temperature, I need to know the name of the city you are interested in.</response>\n",
      "<completed>false</completed>\n",
      "</answer>\n",
      "To provide you with the current temperature, I need to know the name of the city you are interested in.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " Seattle\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========\n",
      "\n",
      " <response>Retrieving the current temperature for Seattle.</response> \n",
      " <tool_call>\n",
      "{\"name\": \"temperature_tool\", \"arguments\": {\"location\": \"Seattle\"}}\n",
      "</tool_call>\n",
      " <completed>false</completed> \n",
      "</answer>\n",
      "==========\n",
      "Prompt: 577 tokens, 99.594 tokens-per-sec\n",
      "Generation: 47 tokens, 10.644 tokens-per-sec\n",
      "Peak memory: 8.694 GB\n",
      "<answer>\n",
      "<response>Retrieving the current temperature for Seattle.</response>\n",
      "<tool_call>\n",
      "{\"name\": \"temperature_tool\", \"arguments\": {\"location\": \"Seattle\"}}\n",
      "</tool_call>\n",
      "<completed>false</completed>\n",
      "</answer>\n",
      "Retrieving the current temperature for Seattle.\n",
      "==========\n",
      "\n",
      " <response>The current temperature in Seattle is approximately 4 degrees Celsius.</response> \n",
      " <completed>true</completed> \n",
      "</answer>\n",
      "==========\n",
      "Prompt: 668 tokens, 103.339 tokens-per-sec\n",
      "Generation: 29 tokens, 11.001 tokens-per-sec\n",
      "Peak memory: 8.694 GB\n",
      "<answer>\n",
      "<response>The current temperature in Seattle is approximately 4 degrees Celsius.</response>\n",
      "<completed>true</completed>\n",
      "</answer>\n",
      "The current temperature in Seattle is approximately 4 degrees Celsius.\n"
     ]
    }
   ],
   "source": [
    "handle_model(messages)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
